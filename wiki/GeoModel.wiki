= Introduction =

The Google Weather API uses zip codes for it's lookup parameter, whereas Google Latitude delivers the data in terms of latitude and longitude. There are various web services, both free and commercial, that can map between these two, but the disadvantage of using an online service is that it's inevitably metered. Therefore, creating a datastore within your app is a nice way to go.

To this purpose,  Moveable Weather uses the CivicSpace US ZIP Code Database, which is released under Creative Commons, and available at http://www.boutell.com/zipcodes/.

However, this only gets us as far as mapping specific zipcodes to specific geographical coordinates. If we are to accept arbitrary US data, coming from Google Latitude, then we need a method for computing proximity.

Along comes the GeoModel Python module to the rescue. Hoever, for GeoModel to do it's work, we need to load all are data into a "geohash". Specifically, we need to make our db object ZipCode, which holds our zip codes, inherit from GeoModel. That's why you'll see the following definition in models.py.

{{{
class ZipCode(GeoModel):
  """A location-aware model for zip codes

  """
  zip = db.StringProperty(required=True)
  city = db.StringProperty(required=True)
  state = db.StringProperty(required=True)
  latitude = db.FloatProperty(required=True)
  longitude = db.FloatProperty(required=True)
  has_location = db.IntegerProperty(required=True)
  timezone =  db.IntegerProperty()
  dst = db.IntegerProperty()
}}}

However, there's one more step in preparing the data, after bulkloading it into the ZipCode datastore. We need to loop through each row in the ZipCode table, calling update_location on it. This is the function that ensures that the latitude and longitude are stored in the geohash used by GeoModel.

The url used to update a  batch of zipcode entities is:

http://moveable-weather.appspot.com/locations_update?limit=LIMIT

where LIMIT is the number of entities to update. By trial and error, I have determined that 100 is a good value for LIMIT, because anything larger tends to cause App Engine to time out. I have created a Makefile target, in the Makefile in the app folder, called "fill". To process update all the zipcode entities, I run the following, in a shell:

{{{
while (1):
   make fill LIMIT=100
}}}


Leave this loop running for about an hour and eventually it will starting saying it is processing 0 entities, which is your way of knowing that it's done.


GeoModel
we load all the locations, using bulkloader
then we iterate through the locations, calling update_location
      """Syncs underlying geocell properties with the entity's location.

    Updates the underlying geocell properties of the entity to match the
    entity's location property. A put() must occur after this call to save
    the changes to App Engine."""


geomodel.py
"""Defines the GeoModel class for running basic geospatial queries on
single-point geographic entities in Google App Engine.

TODO(romannurik): document how bounding box and proximity queries work.
"""

Here's the crucial call

      zip_records = model.ZipCode.proximity_fetch(
                            model.ZipCode.all(),  # Rich query!
                            geo.geotypes.Point(lat, lng),  # Or db.GeoPt
                            max_results=10,
                            max_distance=16000)  # Within 100 miles.




= Details =

Add your content here.  Format your content with:
  * Text in *bold* or _italic_
  * Headings, paragraphs, and lists
  * Automatic links to other wiki pages